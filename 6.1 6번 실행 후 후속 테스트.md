## 워커노드에서도 pod 목록 보기

![alt text](image-16.png)

# k3s 환경 정리 메모 (Ingress + Metrics Server + Kubernetes Dashboard + HPA/노드 확인)

> 이 문서는 대화에서 나온 내용을 한 번에 보기 좋게 정리한 것입니다. (k3s 기준)

---

## 1) k3s에서 Ingress + Metrics Server + Kubernetes Dashboard “mesh up” 관점

### 레이어(역할)로 나누어 이해
- **Edge Ingress 레이어 (외부 → 클러스터)**  
  - 예: **Traefik**(k3s 기본 인그레스)  
  - 외부 HTTP(S) 요청을 받아 **클러스터 Service로 라우팅**
- **App Gateway/Proxy 레이어 (앱 전용 프록시)**  
  - 예: Dashboard Helm chart가 설치하는 **kubernetes-dashboard-kong-proxy**  
  - “클러스터 공용 인그레스 컨트롤러”가 아니라 **Dashboard 앱 앞단 전용 게이트웨이**
- **Observability/Telemetry 레이어 (메트릭 파이프)**  
  - 예: **metrics-server**  
  - kubelet → metrics-server → `metrics.k8s.io` 제공 (`kubectl top`, Dashboard 리소스 그래프에 필요)
- **Dashboard App 레이어**  
  - Dashboard UI 및 관련 컴포넌트들(예: metrics-scraper 등)

### 권장 트래픽 흐름(대표 패턴)
- **Traefik → Service(kong-proxy) → dashboard 내부 서비스**
  - 외부 진입은 Traefik 하나로 통합
  - Dashboard 내부 구조 변경(차트 업그레이드)에도 Ingress 대상은 kong-proxy로 유지 가능

### Helm의 역할
- Helm은 “트래픽 메쉬”가 아니라 **배포/업그레이드/롤백 도구**
- 실제 연결은 Helm이 만든 리소스를 **Ingress(또는 Traefik CRD)**로 “엮어서” 완성

---

## 2) `kubectl apply -f -` 로 적용한 YAML은 worker node에 반영되는가?

### 핵심 개념
- `kubectl apply`로 만든 오브젝트(Deployment/Service/HPA 등)는 **API Server에 저장되는 desired state**
- “노드에 반영”은 그 결과 생성되는 **Pod가 어느 노드에 스케줄링/실행되었는지**로 확인

### 확인 방법(가장 빠름)
```bash
kubectl -n demo-hpa get deploy,rs,pod,svc,hpa -o wide
kubectl -n demo-hpa get pod -o wide
kubectl -n demo-hpa describe pod -l app=nginx
```

---

## 3) 왜 w1만 보이고 w2는 안 쓰였나?

### 결론
- **replicas=2**이면 Pod가 2개뿐이라, 스케줄러가 **cp1 1개 + w1 1개**로 배치할 수 있음
- w2에 “미반영”이 아니라 **배치할 Pod 수가 적어 w2까지 갈 일이 없었던 것**일 가능성이 큼

### w2가 스케줄링 대상인지 체크
```bash
kubectl get nodes -o wide
kubectl describe node w2 | egrep -n "Unschedulable|SchedulingDisabled|Taints"
```
- `Unschedulable: true`면 `kubectl uncordon w2`
- `Taints: ... NoSchedule`가 있으면 일반 Pod가 못 감

### w2에 뜨는 걸 확인하려면
- replica를 늘리기:
```bash
kubectl -n demo-hpa scale deploy/nginx --replicas=3
kubectl -n demo-hpa get pod -o wide
```

---

## 4) vi에서 클립보드 내용을 “깨지지 않게” 정확히 붙여넣기

### 가장 안전: paste 모드
1) `Esc` → `:set paste` → Enter  
2) `i` (입력) → 붙여넣기  
3) 완료 후 `Esc` → `:set nopaste` → Enter

상태 확인:
```vim
:set paste?
```

### 더 안전(vi 자체를 피하고 파일에 그대로 append)
```bash
sudo tee -a /etc/hosts >/dev/null <<'EOF'
192.168.56.10 cp1
192.168.56.11 w1
192.168.56.12 w2
EOF
```

---

## 5) `kubectl apply` 에러 정리

### 5.1 `kubectl apply ./deploy.yaml`
- `apply`는 파일을 직접 인자로 받지 않고 **`-f`가 필요**
```bash
kubectl apply -f ./deploy.yaml
```

### 5.2 `apiVersion not set`
- 파일 내용이 K8s 매니페스트가 아니거나
- 파일 앞부분이 깨져서 첫 리소스의 `apiVersion:`을 인식 못하는 경우

#### 빠른 확인
```bash
sed -n '1,30p' ./deploy.yaml
grep -n "apiVersion" ./deploy.yaml
cat -A ./deploy.yaml | sed -n '1,30p'
```

#### 흔한 원인: BOM/CRLF 제거
```bash
sudo sed -i '1s/^\xEF\xBB\xBF//' ./deploy.yaml
sudo sed -i 's/\r$//' ./deploy.yaml
kubectl apply -f ./deploy.yaml
```

---

## 6) worker node(w1)에서 부하 상태/Pod 확인 가능?

가능합니다. 다만 두 관점이 있습니다.

### A) 클러스터 관점(권장): `kubectl`로 w1에 스케줄된 Pod만 보기
```bash
kubectl get pods -A -o wide --field-selector spec.nodeName=w1
kubectl -n demo-hpa get pods -o wide --field-selector spec.nodeName=w1
```

리소스(메트릭 서버 필요):
```bash
kubectl top node w1
kubectl top pods -A --field-selector spec.nodeName=w1
```

### B) 노드 로컬 관점(k3s agent에서도 즉시 가능): `k3s crictl`
k3s는 containerd 기반이라 Docker 대신 아래를 사용:
```bash
sudo k3s crictl pods
sudo k3s crictl ps
sudo k3s crictl stats --no-stream
sudo k3s crictl logs <CONTAINER_ID>
```

시스템 부하:
```bash
uptime
top
free -h
```

---

## 7) w1에서 `kubectl`이 localhost:8080으로 붙으며 실패하는 이유/해결

### 증상
w1에서:
```bash
kubectl get pods -A -o wide --field-selector spec.nodeName=w1
```
실행 시 `localhost:8080 refused` 발생

### 원인
- w1은 **k3s-agent** 노드이고, API Server는 cp1(server)에 있음
- w1에 올바른 kubeconfig가 없으면 `kubectl`이 기본값(=localhost:8080)으로 시도함

### 해결(권장): cp1 kubeconfig를 w1로 복사 후 server 주소를 cp1 IP로 변경
w1에서(예: cp1 IP가 192.168.56.10인 경우):
```bash
mkdir -p ~/.kube
scp ubuntu@cp1:/etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown -R $USER:$USER ~/.kube
chmod 600 ~/.kube/config

sed -i 's#https://127.0.0.1:6443#https://192.168.56.10:6443#g' ~/.kube/config
sed -i 's#https://localhost:6443#https://192.168.56.10:6443#g' ~/.kube/config

kubectl get nodes
kubectl get pods -A -o wide --field-selector spec.nodeName=w1
```

네트워크 점검(필요 시):
```bash
curl -k https://192.168.56.10:6443/livez
```

---

## 8) HPA 관련 빠른 체크 포인트

HPA 동작 조건:
- metrics-server 정상
- Pod에 `resources.requests.cpu` 설정(이미 YAML에 포함)

확인:
```bash
kubectl get apiservices | grep metrics
kubectl top nodes
kubectl -n demo-hpa top pods
kubectl -n demo-hpa describe hpa nginx-hpa
```

---

### 참고: “w1에서 당장 확인” 최단 루트
- kubeconfig 없이도 바로:
```bash
sudo k3s crictl ps
sudo k3s crictl stats --no-stream
```
- kubeconfig 세팅 후엔:
```bash
kubectl get pods -A -o wide --field-selector spec.nodeName=w1
kubectl top node w1
```
